{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red32\green32\blue32;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c16863\c16863\c16863;\cssrgb\c100000\c100000\c100000;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid102\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid502\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid602\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid702\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid801\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid802\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid901\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid902\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid11}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\b\fs36 \cf0 HDFC 2.x architecture:
\b0\fs24 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls1\ilvl0
\fs32 \cf2 \cb3 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Hadoop 2.x has some common Hadoop API which can easily be integrated with any third party applications to work with Hadoop\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls1\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
It has some new Java APIs and features in HDFS and MapReduce which are known as HDFS2 and MR2 respectively\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
New architecture has added the architectural features like HDFS High Availability and HDFS Federation\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Hadoop 2.x not using Job Tracker and Task Tracker daemons for resource management now on-wards, it is using YARN (Yet Another Resource Negotiator) for Resource Management\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0
\cf2 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs40 \cf2 \cb3 HDFS High Availability (HA)\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b0\fs32 \cf2 \cb3 \ul \ulc2 Problem:\ulnone \'a0 As you know in Hadoop 1.x architecture Name Node was a single point of failure, which means if your Name Node daemon is down somehow, you don\'92t have access to your Hadoop Cluster than after. How to deal with this problem?\cb1 \
\cb3 \ul Solution:\ulnone \'a0 Hadoop 2.x is featured with Name Node HA which is referred as HDFS High Availability (HA).\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Hadoop 2.x supports two Name Nodes at a time one node is active and another is standby node\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Active Name Node handles the client operations in the cluster\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
StandBy Name Node manages metadata same as Secondary Name Node in Hadoop 1.x\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
When Active Name Node is down, Standby Name Node takes over and will handle the client operations then after\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
HDFS HA can be configured by two ways\cb1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\parhyphenfactor20\partightenfactor0
\ls2\ilvl1\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Using Shared NFS Directory\cb1 \
\ls2\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Using Quorum Journal Manager\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0
\cf2 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs40 \cf2 \cb3 HDFS Federation\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b0\fs32 \cf2 \cb3 \ul Problem:\ulnone \'a0 HDFS uses namespaces for managing directories, file and block level information in cluster. Hadoop 1.x architecture was able to manage only single namespace in a whole cluster with the help of the Name Node (which is a single point of failure in Hadoop 1.x). Once that Name Node is down you loose access of full cluster data. It was not possible for partial data availability based on name space.\cb1 \
\cb3 \ul Solution:\ulnone \'a0 Above problem is solved by HDFS Federation i Hadoop 2.x Architecture which allows to manage multiple namespaces by enabling multiple Name Nodes. So on HDFS shell you have multiple directories available but it may be possible that two different directories are managed by two active Name Nodes at a time.\
\
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs40 \cf2 Hadoop 2.x Architecture In Detail\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b0\fs32 \cf2 \cb3 Hadoop2 Architecture has mainly 2 set of daemons\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls3\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
HDFS 2.x Daemons:\'a0 Name Node, Secondary Name Node (not required in HA) and Data Nodes\cb1 \
\ls3\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
MapReduce 2.x Daemons (YARN):\'a0 Resource Manager, Node Manager\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs36 \cf2 \cb3 HDFS 2.x Daemons\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b0\fs32 \cf2 \cb3 The working methodology of HDFS 2.x daemons is same as it was in Hadoop 1.x Architecture with following differences.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls4\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Hadoop 2.x allows Multiple Name Nodes for HDFS Federation\cb1 \
\ls4\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
New Architecture allows HDFS High Availability mode in which it can have Active and StandBy Name Nodes (No Need of Secondary Name Node in this case)\cb1 \
\ls4\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Hadoop 2.x Non HA mode has same Name Node and Secondary Name Node working same as in Hadoop 1.x architecture\
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs36 \cf2 MapReduce 2.x Daemons (YARN)\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b0\fs32 \cf2 \cb3 MapReduce2 has replace old daemon process Job Tracker and Task Tracker with YARN components Resource Manager and Node Manager respectively. These two components are responsible for executing distributed data computation jobs in Hadoop 2\
\
YARN has total three major components\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls5\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
ResourceManager\cb1 \
\ls5\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
NodeManager\cb1 \
\ls5\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
ApplicationMaster\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs40 \cf2 \cb3 1) ResourceManager\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls6\ilvl0
\b0\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
This daemon process resides on the Master Node (not necessarily on NameNode of Hadoop)\cb1 \
\ls6\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Responsible for,\cb1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\parhyphenfactor20\partightenfactor0
\ls6\ilvl1\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Managing resources scheduling for different compute applications in an optimum way\cb1 \
\ls6\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Coordinating with two process on master node, Scheduler and ApplicationManager\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs40 \cf2 \cb3 Scheduler\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls7\ilvl0
\b0\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
This daemon process resides on the Master Node (runs along with ResourceManager daemon )\cb1 \
\ls7\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Responsible for,\cb1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\parhyphenfactor20\partightenfactor0
\ls7\ilvl1\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Scheduling the job execution as per submission request received by \ul ResourceManager\cb1 \ulnone \
\ls7\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Allocating resources to applications submitted to the cluster\cb1 \
\ls7\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Coordinating with \ul ApplicationManager\ulnone  daemon and keeping track of resources of running applications\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs40 \cf2 \cb3 ApplicationManager\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls8\ilvl0
\b0\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
This daemon process resides on the Master Node (runs along with \ul ResourceManager\ulnone  daemon )\cb1 \
\ls8\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Responsible for,\cb1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\parhyphenfactor20\partightenfactor0
\ls8\ilvl1\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Helping Scheduler daemon to keeps track of running application by coordination\cb1 \
\ls8\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Accepting job submissions from client\cb1 \
\ls8\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Negotiating first container for executing application specific task with suitable ApplicationMaster on slave node\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs40 \cf2 \cb3 2) NodeManager\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls9\ilvl0
\b0\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
This daemon process resides on the slave nodes (runs along with DataNode daemon)\cb1 \
\ls9\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Responsible for,\cb1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\parhyphenfactor20\partightenfactor0
\ls9\ilvl1\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Managing and executing containers\cb1 \
\ls9\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Monitoring resource usage (i.e. usage of memory, cpu, network etc..) and reporting it back to \ul ResourceManager\ulnone  daemon\cb1 \
\ls9\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Periodically sending heart-bits to \ul ResourceManager\ulnone  for its health status update\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs40 \cf2 \cb3 3) ApplicationMaster\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls10\ilvl0
\b0\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
This daemon process runs on the slave node (along with the NodeManager daemon)\cb1 \
\ls10\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
It is per application specific library works with \ul NodeManager\ulnone  to execute the task\cb1 \
\ls10\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
The instance of this daemon is per application, which means in case of multiple jobs submitted on cluster, it may have more than one instances of \ul ApplicationMaster\ulnone  on slave nodes\cb1 \
\ls10\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Responsible for,\cb1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\parhyphenfactor20\partightenfactor0
\ls10\ilvl1\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Negotiating suitable resource containers on slave node from \ul ResourceManager\cb1 \ulnone \
\ls10\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Working with one or multiple \ul NodeManagers\ulnone  to monitor task execution on slave nodes\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs40 \cf2 \cb3 What is Container?\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\parhyphenfactor20\partightenfactor0
\ls11\ilvl0
\b0\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
It is considered to be a small unit of resources (like cpu, memory, disk) belong to the SlaveNode\cb1 \
\ls11\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Scheduler process running along with \ul ResourceManager\ulnone \'a0daemon allocates the resources as a container\cb1 \
\ls11\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
At the beginning of a job execution with YARN, container allows \ul ApplicationMaster\ulnone  process to make a use of some resources on any slave node on the cluster\cb1 \
\ls11\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Then \ul ApplicationMaster\ulnone  manages the application execution across other containers on slave nodes of a YARN cluster\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b\fs40 \cf2 \cb3 Brief overview of YARN Architecture\cb1 \
\pard\pardeftab720\parhyphenfactor20\partightenfactor0

\b0\fs32 \cf2 \cb3 let\'92s discuss about step by step Job Execution process in YARN Cluster.\
\
Step 1:\'a0 Job/Application(which can be MapReduce, Java/Scala Application, DAG jobs like Apache Spark etc..) is submitted by the YARN client application to the \cf2 \cb3 \ul \ulc2 ResourceManager\cf2 \cb3 \ulnone  daemon along with the command to start the \cf2 \cb3 \ul \ulc2 ApplicationMaster\cf2 \cb3 \ulnone  on any container at \cf2 \cb3 \ul \ulc2 NodeManager\cf2 \cb1 \ulnone \
\cb3 Step 2:\'a0 \cf2 \cb3 \ul \ulc2 ApplicationManager\cf2 \cb3 \ulnone  process on Master Node validates the job submission request and hand it over to Scheduler process for resource allocation\cb1 \
\cb3 Step 3:\'a0 Scheduler process assigns a container for \cf2 \cb3 \ul \ulc2 ApplicationMaster\cf2 \cb3 \ulnone  on one slave node\cb1 \
\cb3 Step 4:\'a0 \cf2 \cb3 \ul \ulc2 NodeManager\cf2 \cb3 \ulnone  daemon starts the \cf2 \cb3 \ul \ulc2 ApplicationMaster\cf2 \cb3 \ulnone  service within one of its container using the command mentioned in Step 1, hence \cf2 \cb3 \ul \ulc2 ApplicationMaster\cf2 \cb3 \ulnone  is considered to be the first container of any application\cb1 \
\cb3 Step 5:\'a0 \cf2 \cb3 \ul \ulc2 ApplicationMaster\cf2 \cb3 \ulnone  negotiates the other containers from \cf2 \cb3 \ul \ulc2 ResourceManager\cf2 \cb3 \ulnone  by providing the details like location of data on slave nodes, required cpu, memory, cores etc..\cb1 \
\cb3 Step 6:\'a0 \cf2 \cb3 \ul \ulc2 ReourceManager\cf2 \cb3 \ulnone  allocates the best suitable resources on slave nodes and responds to \cf2 \cb3 \ul \ulc2 ApplicationMaster\cf2 \cb3 \ulnone  with node details and other details\cb1 \
\cb3 Step 7:\'a0 Then, \cf2 \cb3 \ul \ulc2 ApplicationMaster\cf2 \cb3 \ulnone  send requests to \cf2 \cb3 \ul \ulc2 NodeManagers\cf2 \cb3 \ulnone  on suggested slave nodes to start the containers\cb1 \
\cb3 Step 8:\'a0 \cf2 \cb3 \ul \ulc2 ApplicationMaster\cf2 \cb3 \ulnone  than manages the resources of requested containers while job execution and notifies the \cf2 \cb3 \ul \ulc2 ResourceManager\cf2 \cb3 \ulnone  when execution is completed\cb1 \
\cb3 Step 9:\'a0 \cf2 \cb3 \ul \ulc2 NodeManagers\cf2 \cb3 \ulnone  periodically notify the \cf2 \cb3 \ul \ulc2 ResourceManager\cf2 \cb3 \ulnone  with the current status of available resources on the node which information can be used by scheduler to schedule new application on the clusters\cb1 \
\cb3 Step 10:\'a0 In case of any failure of slave node \cf2 \cb3 \ul \ulc2 ResourceManager\cf2 \cb3 \ulnone  will try to allocate new container on other best suitable node so that \cf2 \cb3 \ul \ulc2 ApplicationMaster\cf2 \cb3 \ulnone  can complete the process using new container\
}